# @package llm
# HuggingFace GPT-2 configuration

provider: "huggingface"
model: "gpt2"
temperature: 0.7
max_tokens: 256